from datetime import datetime
import tempfile
from typing import Any, Dict, List, Optional
import uuid
from fastapi import APIRouter, BackgroundTasks, Form, HTTPException, Header, UploadFile, File
from fastapi.responses import JSONResponse
import os
import logging

from grpc import Status
from pydantic import BaseModel, Field
from config import CUSTOMER_ID, FILES_DIR
from db.qdrant_service import get_qdrant_client, get_qdrant_client_async
from routes.docs import _process_file
from services.azure_blob_service_async import get_async_blob_service
from services.embeddings_service import ensure_cosine_collection, get_embeddings_from_llama, save_embeddings_with_path
from services.file_service import build_file_structure_tree, normalize_target_path
from services.projects_handler import get_project_file, get_project_file_content
from services.templates_service import TEMPLATES_BASE_DIR, get_template_categories, get_template_metadata, list_all_templates_metadata, list_templates, search_templates, update_template_usage, upload_template_files
from services.text_generation_functions import create_document_from_llm_content, create_filled_document, fill_template_with_llm
from services.utils import extract_text_from_bytes_async, extract_text_from_file

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/templates", tags=["templates"])

class TemplateGenerationRequest(BaseModel):
    template_file_id: str = Field(..., description="ID of the template file to fill")
    source_file_ids: List[str] = Field(..., description="List of source file IDs to use as input")
    project_name: Optional[str] = Field(None, description="Project name for organizing output files")
    output_filename: Optional[str] = Field(None, description="Custom output filename (optional)")
    overwrite_existing: bool = Field(False, description="Overwrite if file with same name exists")
    
class TemplateGenerationResponse(BaseModel):
    success: bool
    message: str
    generation_id: str
    template_file_id: str
    source_file_ids: List[str]
    project_name: str
    generated_at: str
    status_url: str

class GenerationStatusResponse(BaseModel):
    generation_id: str
    status: str  # "processing", "completed", "failed"
    progress: float = Field(0.0, ge=0.0, le=100.0)
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    started_at: str
    completed_at: Optional[str] = None
    estimated_time_remaining: Optional[str] = None

class GeneratedFileInfo(BaseModel):
    fileId: str
    filename: str
    savedAs: str
    path: str
    project: str
    fullPath: str
    size: int
    fileType: str
    created: str
    chunks: int
    metadataSaved: bool
    autoGenerated: bool
    sourceTemplateId: str


@router.post("/upload")
async def upload_templates(
    target_path: str = Form(""),
    category: str = Form(""),
    files: List[UploadFile] = File(...),
    customer_id: str = Header(default="1")  # Or from auth/token
):
    """
    Async upload template files with Azure Blob Storage.
    Supports multiple concurrent uploads.
    """
    try:
        # Validate file types
        valid_extensions = {'.docx', '.doc', '.txt', '.md', '.pdf'}
        invalid_files = []
        
        if not category.strip():
            raise HTTPException(status_code=400, detail="Category is required")
        
        # Quick validation
        for file in files:
            file_ext = os.path.splitext(file.filename)[1].lower()
            if file_ext not in valid_extensions:
                invalid_files.append(file.filename)
        
        if invalid_files:
            return JSONResponse(
                status_code=400,
                content={
                    "error": "Invalid file types",
                    "invalid_files": invalid_files,
                    "allowed_extensions": list(valid_extensions)
                }
            )
        
        # Process files concurrently
        result = await upload_template_files(
            files=files,
            target_path=target_path,
            category=category,
            customer_id=customer_id
        )
        
        # Add validation info
        # result["validated_files"] = len(files) - len(invalid_files)
        # result["invalid_files"] = invalid_files
        
        return JSONResponse(content=result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Template upload failed: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Upload failed: {str(e)}"
        )

@router.get("/metadata/{file_id}")
async def get_template_metadata_endpoint(file_id: str):
    """Get template metadata from Qdrant by file ID"""
    metadata = await get_template_metadata(file_id)
    if not metadata:
        raise HTTPException(status_code=404, detail="Template metadata not found")
    return metadata


@router.get("/metadata")
async def list_templates_metadata(
    category: str = "",
    document_type: str = "",
    complexity: str = ""
):
    """List all templates with metadata from Qdrant"""
    metadata_list = await list_all_templates_metadata(category, document_type, complexity)
    return {
        "filters": {
            "category": category,
            "document_type": document_type,
            "complexity": complexity
        },
        "templates": metadata_list,
        "count": len(metadata_list)
    }

@router.get("/search")
async def search_templates_endpoint(
    query: str = "",
    tags: str = "",
    document_type: str = ""
):
    """Search templates by various criteria"""
    tag_list = [tag.strip() for tag in tags.split(',')] if tags else []
    results = await search_templates(query, tag_list, document_type)
    return {
        "query": query,
        "tags": tag_list,
        "document_type": document_type,
        "results": results,
        "count": len(results)
    }

@router.post("/usage/{file_id}")
async def record_template_usage(file_id: str):
    """Record that a template was used"""
    success = await update_template_usage(file_id)
    return {"success": success, "file_id": file_id}

@router.get("/categories")
async def get_categories():
    categories = await get_template_categories()
    return categories

@router.get("/list")
async def list_all_templates(category: str = ""):
    templates = await list_templates(category)
    return {"category": category or "root", "templates": templates, "count": len(templates)}

@router.get("/{category_name}/files")
async def get_project_files(category_name: str):
    """Get all files in a specific project"""
    try:
        
        collection_name = f"customer_{CUSTOMER_ID}_templates"
 
        result = await build_file_structure_tree(category_name=category_name, collection_name=collection_name )
        
        return result
    except Exception as e:
        logger.error(f"Error retrieving files for category '{category_name}': {e}")
        raise HTTPException(status_code=500, detail=f"Error retrieving project files: {str(e)}")

@router.delete("/{template_path:path}")
async def delete_template(template_path: str):
    try:
        full_path = os.path.join(TEMPLATES_BASE_DIR, template_path)
        if not os.path.exists(full_path):
            raise HTTPException(status_code=404, detail="Template not found")
        if not os.path.isfile(full_path):
            raise HTTPException(status_code=400, detail="Path is not a file")

        absolute_path = os.path.abspath(full_path)
        templates_absolute = os.path.abspath(TEMPLATES_BASE_DIR)
        if not absolute_path.startswith(templates_absolute):
            raise HTTPException(status_code=403, detail="Invalid path")

        os.remove(full_path)
        return {"success": True, "message": f"Template deleted: {template_path}"}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Delete failed: {str(e)}")
    

## Generations 

# In-memory storage for generation status (in production, use Redis or database)
generation_status_store = {}

@router.post(
    "/generate-from-template",
    response_model=TemplateGenerationResponse,
    summary="Generate filled document from template and source files",
    description="Uses LLM to fill a template file with content from source files and saves to project folder"
)
async def generate_from_template(
    request: TemplateGenerationRequest,
    background_tasks: BackgroundTasks
):
    """
    Generate a new document by filling a template with content from source files
    """
    try:
        # Validate input
        if not request.template_file_id:
            raise HTTPException(
                status_code=400,
                detail="Template file ID is required"
            )
        
        if not request.source_file_ids:
            raise HTTPException(
                status_code=400,
                detail="At least one source file ID is required"
            )
        
        if not request.project_name or request.project_name.strip() == "":
            raise HTTPException(
                status_code=400,
                detail="Project name is required"
            )
        
        # Create generation ID for tracking
        generation_id = str(uuid.uuid4())
        
        # Initialize status
        generation_status_store[generation_id] = {
            'generation_id': generation_id,
            'status': 'processing',
            'progress': 0.0,
            'result': None,
            'error': None,
            'started_at': datetime.now().isoformat(),
            'completed_at': None,
            'estimated_time_remaining': None
        }
        
        # Start generation process in background
        background_tasks.add_task(
            process_template_generation,
            generation_id,
            request
        )
        
        logger.info(f"üöÄ Started template generation: {generation_id}")
        logger.info(f"   Template: {request.template_file_id}")
        logger.info(f"   Sources: {len(request.source_file_ids)} files")
        logger.info(f"   Project: {request.project_name}")
        
        return TemplateGenerationResponse(
            success=True,
            message="Template generation started successfully",
            generation_id=generation_id,
            template_file_id=request.template_file_id,
            source_file_ids=request.source_file_ids,
            project_name=request.project_name,
            generated_at=datetime.now().isoformat(),
            status_url=f"/api/templates/generation-status/{generation_id}"
        )
        
    except Exception as e:
        logger.error(f"‚ùå Template generation endpoint error: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to start template generation: {str(e)}"
        )

@router.get(
    "/generation-status/{generation_id}",
    response_model=GenerationStatusResponse,
    summary="Check template generation status",
    description="Get the current status of a template generation process"
)
async def get_generation_status(generation_id: str):
    """
    Check the status of a template generation process
    """
    if generation_id not in generation_status_store:
        raise HTTPException(
            status_code=404,
            detail="Generation ID not found"
        )
    
    status_info = generation_status_store[generation_id]
    return GenerationStatusResponse(**status_info)

@router.get(
    "/generation-history",
    response_model=List[GenerationStatusResponse],
    summary="Get template generation history",
    description="Get history of recent template generation processes"
)
async def get_generation_history(
    limit: int = 10,
    project_name: Optional[str] = None,
    status: Optional[str] = None
):
    """
    Get history of template generation processes
    """
    all_generations = list(generation_status_store.values())
    
    # Apply filters
    filtered_generations = all_generations
    
    if project_name:
        filtered_generations = [
            gen for gen in filtered_generations 
            if gen.get('result', {}).get('project_name') == project_name
        ]
    
    if status:
        filtered_generations = [
            gen for gen in filtered_generations 
            if gen.get('status') == status
        ]
    
    # Sort by start time (newest first) and limit
    filtered_generations.sort(key=lambda x: x['started_at'], reverse=True)
    limited_generations = filtered_generations[:limit]
    
    return [GenerationStatusResponse(**gen) for gen in limited_generations]


# Background task processing
async def process_template_generation(generation_id: str, request: TemplateGenerationRequest):
    """
    Background task to process template generation
    """
    file_path = None
    
    try:
        print(f"üîç DEBUG: Starting template generation {generation_id}")
        
        # Step 1: Validate template file exists
        generation_status_store[generation_id]['progress'] = 10.0
        template_metadata = await get_template_metadata(request.template_file_id)
        if not template_metadata:
            raise ValueError(f"Template file not found: {request.template_file_id}")
        
        template_file_path = template_metadata.get("full_file_path")


        # Step 2: Validate source files exist
        generation_status_store[generation_id]['progress'] = 20.0
        source_files_metadata = []
        for source_file_id in request.source_file_ids:
            source_metadata = await get_project_file(source_file_id)
            if source_metadata:
                source_files_metadata.append(source_metadata)
        
        if not source_files_metadata:
            raise ValueError("No valid source files found")
        
        # Step 3: Extract content from source files
        generation_status_store[generation_id]['progress'] = 30.0
        source_files_content = []
        blob_service = await get_async_blob_service("Projects")
       
        for source_metadata in source_files_metadata:
            file_path_to_read = source_metadata.get("file_path")
            print(f"file_path_to read: {file_path_to_read}")
            if file_path_to_read:
                try:
                    file_content, blob_info = await blob_service.download_file(
                        customer_id=CUSTOMER_ID,
                        blob_name=file_path_to_read
                    )

                    content = await extract_text_from_bytes_async(file_content, filename=blob_info.get("filename"))
                    source_files_content.append({
                        "filename": source_metadata.get("filename", "Unknown"),
                        "content": content,
                        "metadata": source_metadata
                    })
                except Exception as e:
                    print(f"‚ö†Ô∏è Error reading file {file_path_to_read}: {e}")
        
        if not source_files_content:
            raise ValueError("No valid source files found to process")
        
        # Step 4: Generate filled content with LLM
        generation_status_store[generation_id]['progress'] = 50.0
        filled_content = await fill_template_with_llm(
            template_file_path=template_file_path,
            source_files_content=source_files_content,
            template_metadata=template_metadata
        )
        
        # Step 5: Create output document in temp location
        target_path = "generated"
        normalized_target_path = normalize_target_path(target_path)
        
        template_name = template_metadata.get("filename", "template")
        base_name = os.path.splitext(template_name)[0]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"{base_name}_filled_{timestamp}.docx"
        file_id = str(uuid.uuid4())
        
        # Create temp file
        with tempfile.NamedTemporaryFile(mode='wb', delete=False, suffix='.docx') as temp_file:
            temp_file_path = temp_file.name
            create_document_from_llm_content(temp_file_path, filled_content)
        
        print(f"üìÑ Created temp document at: {temp_file_path}")
        
        # Step 6: REUSE the existing _process_file function
        generation_status_store[generation_id]['progress'] = 80.0
        
        # Create a mock UploadFile object for the generated document
        with open(temp_file_path, 'rb') as f:
            file_content = f.read()
        
        # Create an UploadFile object
        from fastapi import UploadFile
        from io import BytesIO
        from starlette.datastructures import Headers
        
        # Create headers with content-type
        headers = Headers({
            "content-type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            "content-disposition": f"form-data; name=\"files\"; filename=\"{output_filename}\""
        })
        
        generated_file = UploadFile(
            filename=output_filename,
            file=BytesIO(file_content),
            headers=headers
        )
        
        # Get blob service
        blob_service = await get_async_blob_service(base_folder="Projects")
        
        # Reuse the existing _process_file function
        collection_name = f"customer_{CUSTOMER_ID}_documents"
        
        # Call the same function used in upload endpoint
        process_result = await _process_file(
            file=generated_file,
            blob_service=blob_service,
            target_project=request.project_name,
            target_path=normalized_target_path,
            collection_name=collection_name
        )
        
        # Clean up temp file
        os.unlink(temp_file_path)
        
        # Check for processing errors
        if "error" in process_result:
            raise ValueError(f"Failed to process generated file: {process_result['error']}")
        
        # Step 7: Update final status with the result from _process_file
        generation_status_store[generation_id]['progress'] = 100.0
        generation_status_store[generation_id]['status'] = 'completed'
        generation_status_store[generation_id]['completed_at'] = datetime.now().isoformat()
        generation_status_store[generation_id]['result'] = {
            "output_file": {
                "fileId": process_result.get("fileId", file_id),
                "filename": output_filename,
                "savedAs": f"{file_id}_{output_filename}",
                "path": normalized_target_path,
                "project": request.project_name,
                "fullPath": process_result.get("blobPath", ""),
                "blobUrl": process_result.get("blobUrl", ""),
                "container": process_result.get("container", ""),
                "size": process_result.get("size", 0),
                "fileType": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                "created": datetime.now().isoformat(),
                "chunks": process_result.get("chunks", 0),
                "metadataSaved": True,
                "autoGenerated": True,
                "sourceTemplateId": template_metadata.get("file_id")
            },
            "template_file_id": request.template_file_id,
            "source_file_ids": request.source_file_ids,
            "project_name": request.project_name,
            "generated_at": datetime.now().isoformat()
        }
        
        print(f"‚úÖ Template generation completed: {generation_id}")
        print(f"   File ID: {file_id}")
        print(f"   Blob URL: {process_result.get('blobUrl')}")
        
    except Exception as e:
        print(f"‚ùå Template generation failed: {generation_id} - {e}")
        import traceback
        print(f"üîç Stack trace: {traceback.format_exc()}")
        
        generation_status_store[generation_id]['status'] = 'failed'
        generation_status_store[generation_id]['completed_at'] = datetime.now().isoformat()
        generation_status_store[generation_id]['error'] = str(e)
        generation_status_store[generation_id]['progress'] = 100.0
        
        # Clean up file if it was created but processing failed
        if file_path and os.path.exists(file_path):
            try:
                os.remove(file_path)
                print(f"üßπ Cleaned up failed file: {file_path}")
            except Exception as cleanup_error:
                print(f"‚ö†Ô∏è  Could not clean up file {file_path}: {cleanup_error}")